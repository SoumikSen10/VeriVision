{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained Haar Cascade classifier for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create the directory to store cropped frames\n",
    "def create_output_dir():\n",
    "    output_dir = os.path.join(os.getcwd(), 'cropped_images')\n",
    "    \n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    return output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to crop faces from frames\n",
    "def detect_and_crop_face(frame, scale_factor=1.4):  # Bounding box expansion by 40%\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    \n",
    "    if len(faces) == 0:\n",
    "        return None\n",
    "    \n",
    "    x, y, w, h = max(faces, key=lambda rect: rect[2] * rect[3])  # Largest face by area\n",
    "    \n",
    "    # Expand bounding box\n",
    "    x = max(0, x - int(w * (scale_factor - 1) / 2))\n",
    "    y = max(0, y - int(h * (scale_factor - 1) / 2))\n",
    "    w = min(frame.shape[1] - x, int(w * scale_factor))\n",
    "    h = min(frame.shape[0] - y, int(h * scale_factor))\n",
    "    \n",
    "    cropped_face = frame[y:y+h, x:x+w]\n",
    "    \n",
    "    return cropped_face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to capture and process frames from each video\n",
    "def process_video_frames(video_path, output_dir, frame_skip=30):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "    video_output_dir = os.path.join(output_dir, video_name)\n",
    "    \n",
    "    if not os.path.exists(video_output_dir):\n",
    "        os.makedirs(video_output_dir)\n",
    "    \n",
    "    frame_count = 0\n",
    "    extracted_frame_count = 0\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        return\n",
    "    \n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    with tqdm(total=total_frames, desc=f\"Processing {video_name}\") as pbar:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            if frame_count % frame_skip == 0:\n",
    "                cropped_face = detect_and_crop_face(frame)\n",
    "                \n",
    "                if cropped_face is not None:\n",
    "                    frame_filename = os.path.join(video_output_dir, f\"frame_{extracted_frame_count}.png\")\n",
    "                    cv2.imwrite(frame_filename, cropped_face)\n",
    "                    extracted_frame_count += 1\n",
    "            \n",
    "            frame_count += 1\n",
    "            pbar.update(1)\n",
    "    \n",
    "    cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to process all videos in the dataset folder\n",
    "def process_all_videos_in_dataset(dataset_dir, frame_skip=30):\n",
    "    output_dir = create_output_dir()\n",
    "    \n",
    "    video_files = [f for f in os.listdir(dataset_dir) if f.endswith(('.mp4', '.avi', '.mov'))]\n",
    "    \n",
    "    for video_file in video_files:\n",
    "        video_path = os.path.join(dataset_dir, video_file)\n",
    "        process_video_frames(video_path, output_dir, frame_skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the dataset folder and frame skip interval\n",
    "dataset_dir = './dataset'\n",
    "frame_skip = 3 # Change this according to your frame skipping requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing id0_0000: 100%|██████████| 469/469 [00:05<00:00, 79.36it/s]\n",
      "Processing id0_0001: 100%|██████████| 303/303 [00:03<00:00, 91.01it/s]\n",
      "Processing id0_0002: 100%|██████████| 350/350 [00:05<00:00, 61.49it/s]\n",
      "Processing id0_0003: 100%|██████████| 529/529 [00:07<00:00, 72.48it/s]\n",
      "Processing id0_0004: 100%|██████████| 326/326 [00:05<00:00, 59.26it/s]\n",
      "Processing id0_0005: 100%|██████████| 459/459 [00:06<00:00, 74.23it/s]\n",
      "Processing id0_0006: 100%|██████████| 534/534 [00:11<00:00, 46.70it/s]\n",
      "Processing id0_0007: 100%|██████████| 479/479 [00:08<00:00, 57.85it/s]\n",
      "Processing id0_0008: 100%|██████████| 464/464 [00:07<00:00, 63.57it/s]\n",
      "Processing id0_0009: 100%|██████████| 520/520 [00:07<00:00, 69.50it/s]\n",
      "Processing id1_0000: 100%|██████████| 371/371 [00:02<00:00, 123.72it/s]\n",
      "Processing id1_0001: 100%|██████████| 276/276 [00:01<00:00, 141.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# Process all videos in the dataset folder\n",
    "process_all_videos_in_dataset(dataset_dir, frame_skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if an image contains a face\n",
    "def contains_face(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray_image, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    \n",
    "    return len(faces) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to delete images without faces from the 'cropped_images' folder\n",
    "def delete_non_face_images(cropped_images_dir):\n",
    "    # Collect all image files from the directory\n",
    "    image_files = []\n",
    "    for root, dirs, files in os.walk(cropped_images_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                image_files.append(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the cropped_images folder\n",
    "cropped_images_dir = './cropped_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete non-face images with progress tracking\n",
    "delete_non_face_images(cropped_images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
